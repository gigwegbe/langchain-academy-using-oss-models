## LangChain Academy with Open-Source Models 
This project updates the LangChain Academy course materials to align with the new LangChain v1.0 API. It demonstrates how to integrate and run open-source language models locally, with support for both Apple Silicon (MacBook M4) and NVIDIA H100 GPU environments. The goal is to deepen understanding of the latest LangChain features while exploring practical deployment workflows for local LLMs

Supported Model Models: 
- OpenAI GPT-OSS 20B
- Qwen series Models

Supported Inference Engines: 
- Ollama 
- vLLM 
- SGLang 

For the development environment and package management, I recommend using uv. It has a bit of a learning curve, but itâ€™s proving to be more efficient and reliable than pip.