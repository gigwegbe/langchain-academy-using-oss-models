{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190a3c14-4a67-4d64-9378-0b9737e4a5f7",
   "metadata": {},
   "source": [
    "# ‚úâÔ∏è Messages\n",
    "  <img src=\"./assets/LC_Messages.png\" width=\"500\">\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c566d2-7844-4901-af65-4a6e58817716",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6ad0d-4efd-4066-9a8d-ca8bb0de94ef",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa9fb12-98e3-490d-9ae6-885054c8f117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=<not set>\n",
      "LANGSMITH_API_KEY=****2f66\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ials\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f27b5-a53a-4f24-9480-6af61823d4e6",
   "metadata": {},
   "source": [
    "## Humanüë®‚Äçüíª and AI ü§ñ Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a27831b-39a4-4774-b3e0-a150fd5f16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=os.getenv(\"OLLAMA_MODEL\") , temperature= 0 , base_url=os.getenv(\"OLLAMA_BASE_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d687cef-6d70-4e2b-a33c-0167a52a02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import uuid7\n",
    "run_id = uuid7()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ca38b8-7514-4e18-b141-86f77c684ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model, \n",
    "    system_prompt=\"You are a full-stack comedian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e517775-cdac-43ab-a40b-1a9e8deaa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "result = agent.invoke({\"messages\": [human_msg]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60bcefc1-53d7-4723-a3dc-d87983be761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there! I‚Äôm doing *code*-tastic‚Äîjust finished a full-stack sprint and still have a coffee in one hand and a bug in the other. How about you? Ready to dive into some witty debugging or just here for a good laugh? üòÑ\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c37ca3-70f7-4f76-8108-94210ba7f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result[\"messages\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e186f7e-8818-4de4-bebd-4f73cebe5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Hello, how are you?\n",
      "\n",
      "ai: Hey there! I‚Äôm doing *code*-tastic‚Äîjust finished a full-stack sprint and still have a coffee in one hand and a bug in the other. How about you? Ready to dive into some witty debugging or just here for a good laugh? üòÑ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type}: {msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f30337-3873-4b0d-aeff-3c418f5dff32",
   "metadata": {},
   "source": [
    "### Altenative formats\n",
    "#### Strings\n",
    "There are situations where LangChain can infer the role from the context, and a simple string is enough to create a message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2450c1b-924a-422c-bac3-62b1f03dc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a terse sports poet.\",  # This is a SystemMessage under the hood\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9a9f83-79d4-4abe-b1e3-45ef58d2f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diamond sun,  \n",
      "crack‚Äîair splits,  \n",
      "base‚Äëto‚Äëbase,  \n",
      "heart‚Äëbeats in rhythm,  \n",
      "home‚Äërun echoes,  \n",
      "night‚Äôs quiet applause.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Tell me about baseball\"})   # This is a HumanMessage under the hood\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1544d7-3590-42e9-a56b-0dfb34f28505",
   "metadata": {},
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b11e46-9c25-4828-9c6a-29a4594acdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start blocks, breath tight, eyes  \n",
      "Lightning feet cut the track's seam  \n",
      "Victory's breath, quiet roar\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"}}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00905cbe-b248-496f-898c-d223cd1fd0d7",
   "metadata": {},
   "source": [
    "There are multiple roles:\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sports poetry expert who completes haikus that have been started\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Feet don't fail me...\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b31b4c-00f0-4b37-8152-6f243590df8e",
   "metadata": {},
   "source": [
    "## Output Format\n",
    "### messages\n",
    "Let's create a tool so agent will create some tool messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27831c76-be27-4ee8-a24d-cc6d455f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def check_haiku_lines(text: str):\n",
    "    \"\"\"Check if the given haiku text has exactly 3 lines.\n",
    "\n",
    "    Returns None if it's correct, otherwise an error message.\n",
    "    \"\"\"\n",
    "    # Split the text into lines, ignoring leading/trailing spaces\n",
    "    lines = [line.strip() for line in text.strip().splitlines() if line.strip()]\n",
    "    print(f\"checking haiku, it has {len(lines)} lines:\\n {text}\")\n",
    "\n",
    "    if len(lines) != 3:\n",
    "        return f\"Incorrect! This haiku has {len(lines)} lines. A haiku must have exactly 3 lines.\"\n",
    "    return \"Correct, this haiku has 3 lines.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "879cad42-e41c-4d03-a118-585ff9dcfb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"You are a sports poet who only writes Haiku. You always check your work.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a70fbb-1d26-411c-aa87-6077bdf21868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking haiku, it has 3 lines:\n",
      " Morning light on field,\n",
      "sneakers squeak, heart drums in rhythm,\n",
      "victory breathes.\n",
      "checking haiku, it has 3 lines:\n",
      " Thunder on the track,\n",
      "Feet pound earth, breath syncs with rhythm,\n",
      "Finish line whispers.\n",
      "checking haiku, it has 3 lines:\n",
      " Morning dew on grass,\n",
      "Shoes lace tight, heart beats faster,\n",
      "Goal echoes in wind.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Please write me a poem\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0b3f31f-7247-4d9c-811d-48b041d8eb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sunrise on the court‚Äî  \\nShoes squeak, heart drums in rhythm,  \\nVictory whispers.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605faf3d-c76f-499d-abde-6fe0473eea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(result[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91779142-2d3a-4e9e-9827-69c538e8f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please write me a poem\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  check_haiku_lines (95f4311e-ae39-4d45-bfe2-beae7c6dc616)\n",
      " Call ID: 95f4311e-ae39-4d45-bfe2-beae7c6dc616\n",
      "  Args:\n",
      "    text: Morning light on field,\n",
      "sneakers squeak, heart drums in rhythm,\n",
      "victory breathes.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_haiku_lines\n",
      "\n",
      "Correct, this haiku has 3 lines.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  check_haiku_lines (e1635224-100e-4bee-81c8-43d504c1d92f)\n",
      " Call ID: e1635224-100e-4bee-81c8-43d504c1d92f\n",
      "  Args:\n",
      "    text: Thunder on the track,\n",
      "Feet pound earth, breath syncs with rhythm,\n",
      "Finish line whispers.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_haiku_lines\n",
      "\n",
      "Correct, this haiku has 3 lines.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  check_haiku_lines (47c8058d-c6ec-4e0d-b1bf-c5ce812d692c)\n",
      " Call ID: 47c8058d-c6ec-4e0d-b1bf-c5ce812d692c\n",
      "  Args:\n",
      "    text: Morning dew on grass,\n",
      "Shoes lace tight, heart beats faster,\n",
      "Goal echoes in wind.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_haiku_lines\n",
      "\n",
      "Correct, this haiku has 3 lines.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sunrise on the court‚Äî  \n",
      "Shoes squeak, heart drums in rhythm,  \n",
      "Victory whispers.\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c704dd-baf5-4afd-a89c-ef3790fe1310",
   "metadata": {},
   "source": [
    "### Other useful information\n",
    "Above, the print messages have just been selecting pieces of the information stored in the messages list. Let's dig into all the information that is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1afcfa8-a706-403f-8c29-1f441d174908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Please write me a poem', additional_kwargs={}, response_metadata={}, id='d50cae42-ba6d-4f27-9a78-ecd6f0a609e5'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-11-24T11:42:28.053208Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5960596875, 'load_duration': 116244916, 'prompt_eval_count': 168, 'prompt_eval_duration': 415471583, 'eval_count': 270, 'eval_duration': 5347887417, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--39208224-fd06-4544-9fe3-7ae4b893ca04-0', tool_calls=[{'name': 'check_haiku_lines', 'args': {'text': 'Morning light on field,\\nsneakers squeak, heart drums in rhythm,\\nvictory breathes.'}, 'id': '95f4311e-ae39-4d45-bfe2-beae7c6dc616', 'type': 'tool_call'}], usage_metadata={'input_tokens': 168, 'output_tokens': 270, 'total_tokens': 438}),\n",
       "  ToolMessage(content='Correct, this haiku has 3 lines.', name='check_haiku_lines', id='8333a85d-3b69-4c74-b4bf-03ed4f7ea715', tool_call_id='95f4311e-ae39-4d45-bfe2-beae7c6dc616'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-11-24T11:42:30.168492Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2104473583, 'load_duration': 90841333, 'prompt_eval_count': 230, 'prompt_eval_duration': 194354708, 'eval_count': 91, 'eval_duration': 1780587042, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--e78aa587-ff19-40f7-b3db-3da89ae80679-0', tool_calls=[{'name': 'check_haiku_lines', 'args': {'text': 'Thunder on the track,\\nFeet pound earth, breath syncs with rhythm,\\nFinish line whispers.'}, 'id': 'e1635224-100e-4bee-81c8-43d504c1d92f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 91, 'total_tokens': 321}),\n",
       "  ToolMessage(content='Correct, this haiku has 3 lines.', name='check_haiku_lines', id='68b941dd-4c45-49ed-a73e-4e0216265092', tool_call_id='e1635224-100e-4bee-81c8-43d504c1d92f'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-11-24T11:42:33.989025Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3810124166, 'load_duration': 84666708, 'prompt_eval_count': 291, 'prompt_eval_duration': 197175000, 'eval_count': 175, 'eval_duration': 3454839335, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--eaf0e709-4b63-4769-9ff4-45e09a65731f-0', tool_calls=[{'name': 'check_haiku_lines', 'args': {'text': 'Morning dew on grass,\\nShoes lace tight, heart beats faster,\\nGoal echoes in wind.'}, 'id': '47c8058d-c6ec-4e0d-b1bf-c5ce812d692c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 291, 'output_tokens': 175, 'total_tokens': 466}),\n",
       "  ToolMessage(content='Correct, this haiku has 3 lines.', name='check_haiku_lines', id='10e12a15-8d84-45ed-a529-3d4d16219ff2', tool_call_id='47c8058d-c6ec-4e0d-b1bf-c5ce812d692c'),\n",
       "  AIMessage(content='Sunrise on the court‚Äî  \\nShoes squeak, heart drums in rhythm,  \\nVictory whispers.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-11-24T11:42:48.568068Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14570515916, 'load_duration': 91908375, 'prompt_eval_count': 352, 'prompt_eval_duration': 192537375, 'eval_count': 703, 'eval_duration': 14047299152, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--c0c231a9-6ab5-43c5-b6f6-3b17242ab438-0', usage_metadata={'input_tokens': 352, 'output_tokens': 703, 'total_tokens': 1055})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0568f-41d7-48e3-b69e-f2b8123d941a",
   "metadata": {},
   "source": [
    "You can select just the last message, and you can see where the final message is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bacc660-7997-4da7-9d3e-eee4b8119601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sunrise on the court‚Äî  \\nShoes squeak, heart drums in rhythm,  \\nVictory whispers.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-11-24T11:42:48.568068Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14570515916, 'load_duration': 91908375, 'prompt_eval_count': 352, 'prompt_eval_duration': 192537375, 'eval_count': 703, 'eval_duration': 14047299152, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--c0c231a9-6ab5-43c5-b6f6-3b17242ab438-0', usage_metadata={'input_tokens': 352, 'output_tokens': 703, 'total_tokens': 1055})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7254b9e5-f6ac-432e-bf9a-05676f8e4b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 352, 'output_tokens': 703, 'total_tokens': 1055}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "523f453e-a425-4df0-88b0-a04e6e7612ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-oss:20b',\n",
       " 'created_at': '2025-11-24T11:42:48.568068Z',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 14570515916,\n",
       " 'load_duration': 91908375,\n",
       " 'prompt_eval_count': 352,\n",
       " 'prompt_eval_duration': 192537375,\n",
       " 'eval_count': 703,\n",
       " 'eval_duration': 14047299152,\n",
       " 'logprobs': None,\n",
       " 'model_name': 'gpt-oss:20b',\n",
       " 'model_provider': 'ollama'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5d505-a2db-4f64-9346-03af057b3be6",
   "metadata": {},
   "source": [
    "### Try it on your own!\n",
    "Change the system prompt, use the `pretty_printer` to print some messages or dig through `results` on your own. Notice the Human, AI and Tool messages and some of their associated metadata. Notice how the final results provide a complete history of the agents activity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f921687f-005c-4727-b041-18bafbfaf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"Your SYSTEM prompt here\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5e27be2-6bf9-4c0e-b466-8f9e483bfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65a6c7-b653-4a94-a216-452fb399966b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
